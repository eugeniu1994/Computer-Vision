{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 8\n",
    "\n",
    "The problems should be solved before the exercise session and solutions returned via\n",
    "MyCourses. For this exercise round you should return a pdf file containing written answers to the questions below. \n",
    "\n",
    "### Exercise 1. Face tracking example using KLT tracker\n",
    "\n",
    "Run the example as instructed below and answer the questions.\n",
    "\n",
    "a) Run ```Exercise8.ipynb```<br>\n",
    "b) Run ```Exercise8.ipynb``` with a different input by changing the input to obama.avi: ```frames=faceTracker('obama.avi')```<br>\n",
    "c) What could be the main reasons why most of the features are not tracked very long in case b) above?<br>\n",
    "d) How could one try to avoid the problem of gradually losing the features? Suggest one or more improvements.<br>\n",
    "e) Voluntary task: Capture a video of your own face or of a picture of a face, and check that whether the tracking works for you. That is, replace the input video path in ```faceTrackingDemo.py``` with the path to your own video. \n",
    "\n",
    "### Exercise  2. Kanade-Lucas-Tomasi  (KLT)  feature  tracking  (Pen  &  paper  problem)\n",
    "Read Sections 2.1 and 2.2 from the [paper by Baker and Matthews](https://www.ri.cmu.edu/pub_files/pub3/baker_simon_2002_3/baker_simon_2002_3.pdf). Show that the Equation (10) in the paper gives the same solution as the equations on slide 25 of Lecture 7, when the geometric warping W \n",
    "(between the current frame and the template window in the previous frame) is a translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from faceTrackingDemo import faceTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`min_samples` must be in range (0, <number-of-samples>)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-cffdf5f26a68>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m#frames = faceTracker('santi.avi')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m#frames = faceTracker('obama.avi')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfaceTracker\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'myVid.avi'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/MyCourses/1_CV/EX8/faceTrackingDemo.py\u001B[0m in \u001B[0;36mfaceTracker\u001B[0;34m(input_file)\u001B[0m\n\u001B[1;32m     84\u001B[0m                 \u001B[0;31m# the new points and eliminate outliers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m                 tform, inliers = ransac((oldInliers, visiblePoints), SimilarityTransform, min_samples=2,\n\u001B[0;32m---> 86\u001B[0;31m                                    residual_threshold=2, max_trials=200)\n\u001B[0m\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m                 \u001B[0mH1to2p\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtform\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/skimage/measure/fit.py\u001B[0m in \u001B[0;36mransac\u001B[0;34m(data, model_class, min_samples, residual_threshold, is_data_valid, is_model_valid, max_trials, stop_sample_num, stop_residuals_sum, stop_probability, random_state, initial_inliers)\u001B[0m\n\u001B[1;32m    796\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    797\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mmin_samples\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mnum_samples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 798\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"`min_samples` must be in range (0, <number-of-samples>)\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    799\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    800\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mresidual_threshold\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: `min_samples` must be in range (0, <number-of-samples>)"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# frames of the processed input video\n",
    "# change the input to obama.avi in part b)\n",
    "#frames = faceTracker('santi.avi')\n",
    "#frames = faceTracker('obama.avi')\n",
    "frames = faceTracker('myVid.avi')\n",
    "\n",
    "\n",
    "# create an animation that can be embedded in the notebook\n",
    "ani = animation.ArtistAnimation(fig, frames, interval=50, blit=True, repeat_delay=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ani' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-044af5c14a67>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mHTML\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mani\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_html5_video\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ani' is not defined"
     ]
    }
   ],
   "source": [
    "display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}